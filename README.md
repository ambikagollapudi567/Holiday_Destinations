# Holiday_Destinations

In the current repository I have extracted the data from one of the website using web-scraping technique and finally saved the file into a .csv file for further processing and analysis.

# Steps:

    .Identify the website to be scraped.

    .Identify the feature to be extracted from the data.

    .For example, In the current repository I am extracting following features.

                1. Holiday Destination place.
     
                2. Country.
      
    .Extracting the data from the html tags.
    
    .Cleaning  the data.

    .Saving the file into a .csv file for further processing.
    
 # Dependencies:
    .Pandas
    .BeautifulSoup
    .Urllib
    
# Note:

Installing Anaconda Distribution will resolve all the dependencies. Code changes and modifications needed depending on the layout of the web page and placement of the features in the given web page.
